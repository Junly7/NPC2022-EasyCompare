\section{Code Transformer}
\label{sec:codetran}

In this section, we propose a code transformer based on LLVM Clang to transform GUC DSL into executable Python codes of GNN frameworks. The core idea of the transcoder is that GNNs implemented by different frameworks share the same structure defined by GUC DSL. The solution is to transform the interfaces (e.g., \textsl{GCNConv}) in GUC DSL into functionally equivalent interfaces (e.g., \textsl{GraphConv} in DGL and \textsl{GCNConv} in PyG) with necessary parameters.

The Clang (the front-end of the LLVM compiler) is leveraged to modify the original code. Figure~\ref{fig:gcn_python} shows the transformed codes of the GCN example in Figure~\ref{fig:gcn_guc}, where the modification details are highlighted. The code transformer adds basic syntaxes and makes no changes to the conforming Python paradigms. More importantly, the code transformer automatically replaces GUC interfaces by the exact interfaces with corresponding parameters to maintain functional equivalence between frameworks.

The code transformer supports mini-batch training with graph partitioning in addition to full-graph training. In such scenarios, datasets are automatically batched with \textsl{NeighborSampler}~\cite{hamilton2017inductive} according to user-defined settings.

%GUC supports mini-batch training with batch sizes. According to the batch size defined by users and fixed settings, datasets will be automatically batched with \textsl{NeighborSampler}~\cite{hamilton2017inductive}.

\lstset{
emph={self,GraphConv,nn,bias,norm,normalize,g,edge_index},
emphstyle=\color{blue}
}
\begin{figure}[!ht]
  \centering
  \begin{minipage}[c]{1\textwidth}
    \begin{lstlisting}
class NET(nn.Module):
  def __init__(self,in_feat,out_feat):
    super().__init__()
    self.conv1=GCNConv(in_feat,16,bias=True,normalize=True)
    self.conv2=GCNConv(16,out_feat,bias=False,normalize=True)
    self.relu1=nn.ReLU()
    self.relu2=nn.LeakyReLU(0.5)

  def forward(self,edge_index,h):
    h=self.relu1(self.conv1(h,edge_index))
    h=self.relu2(self.conv2(h,edge_index))
    return h
    \end{lstlisting}
    \subcaption{\centering GCN implementation in PyG}
  \end{minipage}

  \begin{minipage}[c]{1\textwidth}
    \begin{lstlisting}
class NET(nn.Module):
  def __init__(self,in_feat,out_feat):
    super().__init__()
    self.conv1=GraphConv(in_feat,16,bias=True,norm=True)
    self.conv2=GraphConv(16,out_feat,bias=False,norm=True)
    self.relu1=nn.ReLU()
    self.relu2=nn.LeakyReLU(0.5)

  def forward(self, g, h):
    h=self.relu1(self.conv1(g,h))
    h=self.relu2(self.conv2(g,h))
    return h;
    \end{lstlisting}
    \subcaption{\centering GCN implementation in DGL}
  \end{minipage}
  \caption{Code transformation of the GCN example.}
  \label{fig:gcn_python}
\end{figure}
