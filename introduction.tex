\section{Introduction}
\label{sec:introduction}
In recent years, Graph Neural Networks (GNNs)~\cite{wu2020comprehensive} have been widely adopted in many aspects, such as node classification, edge classification and link prediction. Different from traditional deep neural networks (DNNs) that operate on Euclidean data (e.g.,1D text and 2D images), GNNs are trained on non-Euclidean data (e.g., social-network graphs and knowledge graphs). GNNs generally involve highly memory-intensive graph operations, which makes them difficult to achieve high performance on many-core processors (e.g., GPUs).

%With the wide use of GNN, the performance of GNN is getting more and more attention.

%Popular GNN models include GCN~\cite{kipf2016semi}, GraphSAGE~\cite{hamilton2017inductive}, GAT~\cite{velivckovic2017graph} and GIN~\cite{xu2018powerful}.
The performance optimization of GNNs has gradually attracted attention. The GNN performance is affected by a variety of factors such as framework designs and GPU architectures. For example, the mainstream GNN frameworks including PyTorch Geometric (PyG)~\cite{fey2019fast} and Deep Graph Library (DGL)~\cite{wang2019deep} have different graph operator implementations and layer optimization strategies. In addition, GPUs with different hardware architectures have a impact on the performance of GNNs. The GNN performance may be significantly degraded due to memory bandwidth contention or cache conflicts.

%First, the NN framework of a GNN model can have an impact on model performance. Nowadays, the mainstream frameworks of GNN include PyG~\cite{fey2019fast} and DGL~\cite{wang2019deep}. Although both of PyG and DGL are based on PyTorch, there exists many differences in the specific implementation, for example, PyG and DGL have different operator combination and optimization scheme of network layers of GNN. In addition, the hardware device GNN model trained on can also affect the performance of the model. For example, different GPUs structure may actually impact on the training and inference of GNN models and result in significant differences of model performance.

Multi-dimensional performance comparisons of GNN models are important for both users and researchers. On the one hand, by comparing the performance of GNN models on different frameworks and GPUs, users can make informed framework and GPU choices. On the other hand, the operator-level performance comparison of GNN frameworks helps researchers dig out the potential impact of the framework implementation. In this way, researchers can explore further optimization paths for GNN frameworks. However, the performance comparison of GNN models in frameworks and GPUs has the following challenges.

\textbf{Inconsistent language styles between frameworks.} PyG and DGL have different code organization and interface definitions. Large manual efforts are required to make the same GNN structure functionally equivalent on different frameworks. This prevents users from quickly achieving a fair comparison of framework performance.

\textbf{Lack of performance analysis systems.} A comprehensive performance comparison requires deploying GNN models implemented with multiple GNN frameworks on diverse GPUs. Furthermore, log recycling and result visualization are tedious and tricky for bother users and researchers. Finally, we implement an integrated system that can run GNN models on various GPUs and visualize performance logs for better comparison and analysis.

To this end, we propose EasyCompare to achieve high efficiency for GNN performance comparison and result analysis. First, we design a Domain Specific Language (DSL) called GUC (\underline{G}NN \underline{U}nified Language based on \underline{C}$++$), which enables the convenient definition of GNN models. Then, we develop a code transformer to automatically convert GUC DSL into execuable Python codes on DGL and PyG frameworks. Finally, we implement an integrated system that run GNN models on various GPUs and visualize performance logs for better analysis. With EasyCompare, we conduct extensive experiment to deeply explore the factors that influence the performance of GNN models. The insights from experiments provide useful suggestions for optimizing GNN frameworks on GPUs.

%\textcolor{blue}{The results show that:}
%
%\textcolor{blue}{1. DGL is more memory-friendly than PyG, and runs faster due to its different selection of operators though PyG has a high GPU usage. }
%
%\textcolor{blue}{2. When dealing with datasets that are denser and have more node features, DGL tends to use GSpMM while PyG tends to use scatter-gather related operators which will generate more message tensors.}
%
%\textcolor{blue}{3. For GPU cost-efficiency, DGL on V100 performs better than A100 while PyG on A100 performs better than V100.}
The rest of this paper is organized as follows. Section~\ref{sec:background} presents the background. Sections~\ref{sec:gnndsl}-\ref{sec:system} present the details of EasyCompare implementation. Section~\ref{sec:evaluation} presents the evaluation results. Section~\ref{sec:conclusion} concludes this paper.
%\textcolor{blue}{The rest of this paper is organized as follows. Section \ref{sec:background} presents the background of GNNs and GNN frameworks. Section \ref{sec:gnndsl}, Section \ref{sec:codetran} and Section \ref{sec:system} introduce the implementation of EasyCompare. Section \ref{sec:evaluation} presents the results of experiments based on EasyCompare, and Section \ref{sec:conclusion} concludes this paper.}
