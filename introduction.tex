\section{Introduction}
\label{sec:introduction}
In recent years, Graph Neural Networks (GNNs) have been widely adopted in many aspects, such as node classification, edge classification, and link prediction. Different from traditional deep neural networks (DNNs) that operate on Euclidean data (e.g.,1D text and 2D images), GNNs are trained on non-Euclidean data (e.g., social-network graphs and knowledge graphs). Moreover, GNNs generally involve highly memory-intensive graph operations, making it challenging to achieve high performance on many-core processors (e.g., GPUs).

The performance optimization of GNNs has gradually attracted attention. The GNN performance is affected by various factors such as framework designs and GPU architectures. For example, the mainstream GNN frameworks, including PyTorch Geometric (PyG)~\cite{fey2019fast} and Deep Graph Library (DGL)~\cite{wang2019deep} have different graph operator implementations and layer optimization strategies. In addition, GPUs with varying architectures of hardware impact the performance of GNNs. For instance, memory bandwidth contention or cache conflicts may significantly degrade the GNN performance.

Multi-dimensional performance comparisons of GNN models are essential for both users and researchers. On the one hand, by comparing the performance of GNN models on different frameworks and GPUs, users can make the informed framework and GPU choices. On the other hand, the operator-level performance comparison of GNN frameworks helps researchers determine the framework implementation's potential impact. In this way, researchers can explore further optimization paths for GNN frameworks. However, the performance comparison of GNN models in frameworks and GPUs has the following challenges.

\textbf{Inconsistent language styles between frameworks.} PyG and DGL have different code organization and interface definitions. As a result, great manual efforts are required to make the same GNN structure functionally equivalent on different frameworks. The inconsistent language styles between frameworks prevent users from quickly achieving a fair comparison of framework performance.

\textbf{Lack of performance analysis systems.} A comprehensive performance comparison requires deploying GNN models implemented with multiple GNN frameworks on diverse GPUs. Furthermore, log recycling and result visualization are tedious and tricky for users and researchers. Finally, we implement an integrated system that can run GNN models on various GPUs and visualize performance logs for better comparison and analysis.

To this end, we propose EasyCompare to achieve high efficiency for GNN performance comparison and result analysis. First, we design a Domain Specific Language (DSL) called GUC (\underline{G}NN \underline{U}nified Language based on \underline{C}$++$), which enables the convenient definition of GNN models. Then, we develop a code transformer to automatically convert GUC DSL into executable Python codes on DGL and PyG frameworks. Finally, we implement an integrated system that runs GNN models on various GPUs and visualizes performance logs for better analysis. With EasyCompare, we conduct extensive experiments to deeply explore the factors that influence the performance of GNN models. The insights provide useful suggestions for optimizing GNN frameworks on GPUs.

%The rest of this paper is organized as follows. Section~\ref{sec:background} presents the background. Sections~\ref{sec:gnndsl}-\ref{sec:system} present the details of EasyCompare implementation. Section~\ref{sec:evaluation} presents the evaluation results. Section~\ref{sec:conclusion} concludes this paper.
