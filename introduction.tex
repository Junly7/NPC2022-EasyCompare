\section{Introduction (1 pages)}
\label{sec:introduction}
In recent years, the application of Graph Neural Networks (GNNs) in many aspects has reached the state-of-the-art level, such as node classification, edge classification and link prediction. Different from traditional deep neural networks that operate on Euclidean data (e.g.,1D text and 2D images), GNNs are trained on non-Euclidean data (e.g., social-network graphs and knowledge graphs). Popular GNN models include GCN~\cite{kipf2016semi}, GraphSAGE~\cite{hamilton2017inductive}, GAT~\cite{velivckovic2017graph} and GIN~\cite{xu2018powerful}. With the wide use of GNN, the performance of GNN is getting more and more attention.

The performance of GNN models is affected by a variety of factors. First, the NN framework of a GNN model can have an impact on model performance. Nowadays, the mainstream frameworks of GNN include PyG~\cite{fey2019fast} and DGL~\cite{wang2019deep}. Although both of PyG and DGL are based on PyTorch, there exists many differences in the specific implementation, for example, PyG and DGL have different operator combination and optimization scheme of network layers of GNN. In addition, the hardware device GNN model trained on can also affect the performance of the model. For example, different GPUs structure may actually impact on the training and inference of GNN models and result in significant differences of model performance.

It's important to evaluate the performance of GNN models. On the one hand, by comparing GNN models' performance on different frameworks and hardware, users can choose GNN framework and hardware for a better performance of their models. On the other hand, the results of comparison of GNN frameworks may help scholars to better understand the performance factors behind the framework designs and search for a further optimization direction of GNNs or frameworks.

We ascertain two major challenges of comparing the performance of GNN models with various GNN frameworks and hardware.

\textbf{Language styles of frameworks vary greatly.} Different frameworks have different interface definitions and code organization structures for the implementation of GNN, making it difficult to build GNN models sharing same network structure on different frameworks for a fair framework performances comparison. 

\textbf{Lack of efficient performance comparison analysis tools.} Multiple GNN frameworks, hardware devices and GNN models are needed during comparison, which is a huge workload to conduct comparison and it's tricky to record and organize various useful data during the comparison.

To this end, we propose EasyCompare to increase efficiency of comparison and help to analyse results. First, we propose a Domain Specific Language (DSL) called GUC (GNN Unified language based on C++), with which we are able to define various GNN models conveniently. Then, we propose a code transformer to automatically convert GUC DSL into execuable Python code on DGL and PyG frameworks. Finally, we propose an integrate system to run GNN models on different devices and record the operating data for a better analysis. 

Based on EasyCompare, we conduct extensive experiment to explore the factors that influence the performance of GNN models. The results show that...
