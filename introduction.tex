\section{Introduction (1 pages)}
\label{sec:introduction}
In recent years, the application of Graph Neural Networks (GNNs) in many aspects has reached the state-of-the-art level, such as node classification, edge classification and link prediction. Different from traditional deep neural networks that operate on Euclidean data (e.g.,1D text and 2D images), GNNs are trained on non-Euclidean data (e.g., social-network graphs and knowledge graphs). Popular GNN models include GCN~\cite{kipf2016semi}, GraphSAGE~\cite{hamilton2017inductive}, GAT~\cite{velivckovic2017graph} and GIN~\cite{xu2018powerful}. With the wide use of GNN, the performance of GNN is getting more and more attention.

The performance of GNN models is affected by a variety of factors. First, the NN framework of a GNN model can have an impact on model performance. Nowadays, the mainstream frameworks of GNN include DGL and PyG. Although both of DGL and PyG are based on PyTorch, there exists many differences in the specific implementation, for example, DGL and PyG have different operator combination and optimization scheme of network layers of GNN. In addition, the hardware device GNN model trained on can also affect the performance of the model. For example, different GPUs structure may actually impact on the training and inference of GNN models and result in significant differences of model performance.

It's important to evaluate the performance of GNN models. On the one hand, the comparative analysis of model performance can help users and enterprises to quickly choose a suitable GNN framework, saving manpower and time; on the other hand, before purchasing or leasing expensive GPUs resources, users will want to know which GPU is the best for model tasks and make more informed choices. More importantly, the results of comparison of GNN frameworks may help to guide the further optimization direction of the frameworks.

We ascertain two major challenges of comparing the performance of GNN models. First, language styles vary greatly under different frameworks. Different frameworks have different interface definitions and code organization structures for the implementation of GNN. Second, lack of efficient performance comparison analysis tools. Multiple GNN frameworks ,hardware devices and GNN models are used during comparison, which is a huge workload to record and organize various running data.

To this end, we propose EasyCompare to increase efficiency of comparison and help to analyse results. First, we propose a Domain Specific Language (DSL) called GUC (GNN Unified language based on C++). We are able to define various GNN models on GUC DSL conveniently. Then, we propose a code conversion tool to automatically convert GUC DSL into runnable Python code under DGL and PyG frameworks. Finally, we propose an integrate system to run GNN models on different devices and record the operating data.

Based on EasyCompare, we conduct extensive experiment to explore the factors that influence the performance of GNN models. The results show that...
