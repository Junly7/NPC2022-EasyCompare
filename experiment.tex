\section{Evaluation (3 pages)}
\label{sec:evaluation}

\subsection{Experiment Setup}
\label{sec:setup}

% ƫС�����ݼ�������GPU�ŵ��£�(6-8��)��full graph training���������ݼ���1-2������mini-batch training
\subsubsection{Hardware and software configurations}
We conducte evaluation on two servers equipped with two types of GPUs, as shown in Table \ref{tab:The GPUs used for evaluation}.
The GPU rental fee is based on Google Cloud Server~\cite{googlecloud2022}.
Both of the server is equipped with E5-2680 v4 @ 2.4Hz, 28 cores and 256 GB main memory.

\begin{table}
    \centering
    \vspace{-1cm} %调整与上文的垂直距离
    \caption{The GPUs used for evaluation}
    \label{tab:The GPUs used for evaluation}
    \setlength{\tabcolsep}{7.mm}{
        \begin{tabular}{|c|c|c|c|}
            \hline
            GPU & Mem. & TFLOPS & Rental \\
            \hline
            V100 & 16GB HBM2 & 7.8 & \$2.48\/hr \\
            A100 & 40GB HBM2 & 9.7 & \$2.934\/hr \\
            \hline
        \end{tabular}
    }
    \vspace{-1cm}
\end{table}



\subsubsection{GNN configurations and graph datasets}
Small, medium, large and oversized datasets were selected for evaluation in the experiment to ensure the universality of results.
The datasets and their specifications are shown in Table \ref{tab:Datasets used for evaluation}.
Four typical GNN models introduced above, GAT, GCN, GIN and GraphSAGE, were used in the experiment.
The GNN models are implemented by PyG and DGL while ensuring model alignment (2 Conv with ReLU activation function).

\begin{table}
    \vspace{-0.8cm} %调整与上文的垂直距离
    \centering
    \caption{Datasets used for evaluation}
    \label{tab:Datasets used for evaluation}
    \setlength{\tabcolsep}{7.mm}{
        \begin{tabular}{|c|c|c|c|}
            \hline
            Dataset & \#Nodes & Sizes & Scale \\
            \hline
            PubMed & 19,717 & 41,086,414 & small \\
            PPI & 56,944 & 18,895,872 & small \\
            arXiv & 169,343 & 109,494,272 & middle \\
            DD & 334,925 & 138,411,008 & middle \\
            COLLAB & 235,868 & 165,507,072 & middle \\
            PPA & 576,289 & 827,491,328 & large \\
            PROTEINS & 132,534 & 1,273,385,984 & large \\
            reddit.dgl & 232,965 & 2,400,594,432 & oversized \\
            Products & 2,449,029 & 3,017,921,024 & oversized \\
            \hline
        \end{tabular}
    }
    \vspace{-0.7cm} %调整与下文的垂直距离
\end{table}


\subsubsection{Comparison metrics}
The experiment will use two GPUs to measure the performance of training multiple datasets under four GNNs, including time overhead, GPU utilization and peak memory consumption.
In addition, operator occupancy breakdown analysis will be performed to show the differences in GNNs implementation between the two frameworks.
Finally, according to the results above, a case study on cost-efficiency under different GPUs will be conducted.

\subsection{Framework Comparison}
\label{sec:frameworkcomp}
% ע��˵����EasyCompare�ſ�����������֮���Ĺ����ԱȺͿ��ӻ��������û���������ѡ�������ܷ���
% (on V100) Compare PyG with DGL, including execution time, GPU utilization, memory usage ... 3 * 4 figures
% Analyse the reasons of experiment results, from the perspective of framework design (e.g., graph operator implementation)
\begin{figure}
    \vspace{-0.8cm} %调整图片与上文的垂直距离
    \centering
    
    \begin{minipage}[c]{1\textwidth}
        
        \includegraphics[width=\textwidth]{images/full_graph_memory.pdf}
        \subcaption{Peak memory consumption.}
        \label{fig:full_graph_memory}      
        

        \includegraphics[width=\textwidth]{images/full_graph_time.pdf}
        \subcaption{Exection time.}
        \label{fig:full_graph_time}

        \includegraphics[width=\textwidth]{images/full_graph_gpu.pdf}
        \subcaption{GPU utilization.}
        \label{fig:full_graph_gpu}
        
        
    \end{minipage}
    
    \caption{Full-graph training of 128 epoches on V100, OOM means out-of-memory.}
    \label{fig:full_graph}
    
    \vspace{-1cm} %调整图片与下文的垂直距离
\end{figure}

\subsubsection{Full-graph Training}
As shown in Figure \ref{fig:full_graph}, in full-graph training, we measure the training metrics on GPU of 128 epoches.
For execution time, DGL is slower by a small margin (8\%-15\%, except GAT in which DGL gets 1.2$\times$ faster) in training the small and medium-sized datasets which is due to framework overhead~\cite{wang2019deep}.
For large datasets, DGL is 1.45-2.2$\times$ faster than PyG, because DGL adopts GSpMM operator to avoid generating message tensors while PyG's scatter-gather operator does(explained in Section \ref{sec:op_breakdown} Figure \ref{fig:op_breakdown}).
It also explains why PyG runs out-of-memory in GAT on large datasets due to PPA and PROTEINS are denser and have more edge features.

For peak memory consumption, it is obvious that DGL has a more powerful memory management for GNNs that PyG consumes about 2-6$\times$ more memory than DGL.
DGL manages to keep a low memory footprint due to its GSpMM operator fusing the message computation with aggregation.

For GPU Utilization, PyG occupies GPU more frequently and completely than DGL.
PyG achieve 1.2-1.9x of more GPU Utilization.
A deeper look at the GPU utilization curve shows that the two curves almost coincide with each other from 0 to 100\% during training.
However, because DGL often finishes training faster, the utilization will be lower when calculating the average value.



\subsubsection{Mini-batch Training} %(on V100) Compare PyG with DGL, only execution time, 1 * 4 figures
Figure \ref{fig:minibatch_time} evaluates only the execution time of mini-batch training.
We use neighbor sampling (NS) and set mini-batch size to 10240 to train 8 epoches to obtain the measurement data.
The total execution time also depends on the cost of sample preparation, including sampling operations and data movement from CPU to GPU, compared to full graph training.
For NS, sample generation and data movement can occupy up to 85\% of the total training time while GPU Utilization hovers between 0 and 30\% which accounts for the significant performance degradation.

\begin{figure}
    \vspace{-0.5cm} %调整图片与上文的垂直距离
    \centering
    \includegraphics[width=\textwidth]{images/minibatch_time.pdf}
    \caption{Mini-batch training of 8 epoches on V100, only shows execution time.}
    \label{fig:minibatch_time}
    \vspace{-1cm} %调整图片与下文的垂直距离
\end{figure}


\subsection{Operator Breakdown}
\label{sec:op_breakdown}
% (on V100) PyG, DGL, Top-10/20 operator intesection (4-6 operators each figure), 2 * 4 figures
For the DGL and PyG, we counted the proportion of operators in their respective training process and selected the top 5 operators respectively for horizontal comparison.
As shown in Figure \ref{fig:op_breakdown}, DGL has obvious characteristics in selecting operators.
For small and medium-sized data sets, the occupancy of GSpMM operators is about 20\%, and for denser datasets, it reaches 60\%-80\%.
The top 3 operators of DGL account for almost 60\% or even more than 80\%.
The operator proportion of PyG is relatively dispersed and PyG shows more scatter-gather operators while dealing with denser datasets.
Due to the gigantic real world graph, DGL developed fused message passing technique and consolidated it with sparse matrix computation into generalized sparse-dense matrix multiplication (g-SpMM) in order to reducing memory traffic.
It accounts for that DGL can achieves much more better performance (in execution time and peak memory consumption) in denser and more edge features datasets.

In addition, we found that training in GAT performs worse than other GNNs (i.e. high peak memory consumption, execution time and dispersive ratio of operators) in Figure \ref{fig:full_graph} and Figure \ref{fig:op_breakdown}.
\textsl{GATConv} scales bad by design, as autograd needs to hold tensors of shape \textsl{[num\_edges, num\_heads, 2*num\_features]} in memory.
There is no real solution to prevent this, as we need to compute attention scores for each edge and each head, based on pair-wise node features.
All conv operators will scale up by edges if they depend on pair-wise node features or edge features.
However, in \textsl{GCNConv}, it can be implemented much more memory-friendly as this operator does not require mapping node features into edge space, e.g., by using sparse-matrix multiplications.

\begin{figure}
    \vspace{-0.5cm} %调整图片与上文的垂直距离
    \centering
    \begin{minipage}[c]{1\textwidth}
        \includegraphics[width=\textwidth]{images/op_breakdown_dgl.pdf}
        \subcaption{dgl breakdown}
        \label{fig:op_breakdown_dgl}

        \includegraphics[width=\textwidth]{images/op_breakdown_pyg.pdf}
        \subcaption{pyg breakdown}
        \label{fig:op_breakdown_pyg}
    \end{minipage}
    \caption{op breakdown}
    \label{fig:op_breakdown}
    \vspace{-1cm} %调整图片与下文的垂直距离
\end{figure}

\subsection{Case Study: Cloud GPU Selection}
\label{sec:casestudy}
% ע��˵����EasyCompare���Է�����������ͬGPU�����ܶԱȣ������û�����GPUѡ��
% (only full-graph training) Compare V100 with A100, considering pure performance and cost efficiency, 2 * 4 figures
% Analyse the reasons of experiment results, from the perspective of hardware details, computational characteristics of GNNs
Currently, most researchers consider renting cloud GPU servers to run deep learning tasks.
This case study will simply explain the computing characteristics of GNNs and the selection of cloud servers based on the metric results of two different GPU in Table \ref{tab:The GPUs used for evaluation}.

\begin{figure}
    \vspace{-0.8cm} %调整图片与上文的垂直距离
    \centering
    \begin{minipage}[c]{1\textwidth}
        \includegraphics[width=\textwidth]{images/pure_performance.pdf}
        \subcaption{pure performance}
        \label{fig:pure_performance}

        \includegraphics[width=\textwidth]{images/cost_efficiency.pdf}
        \subcaption{cost efficiency}
        \label{fig:cost_efficiency}
    \end{minipage}
    \caption{op breakdown}
    \label{fig:case_study}
    \vspace{-0.8cm} %调整图片与下文的垂直距离
\end{figure}

\subsubsection{Pure Performance}
Figure \ref{fig:pure_performance} shows the pure performance of V100 and A100 based on PROTEINS (There is no comparison of small or medium-sized datasets because they almost perform the same and except GAT because of PyG's out-of-memory).
A100 is 1.2$\times$ faster than V100 on average which confirms improvement of GPU TFLOPS.
Due to the computing characteristics of GNN are memory intensive, GPU utilization on V100 is lower than that on A100.


\subsubsection{Cost Efficiency}
Based on the pure performance and the rental price in Table \ref{tab:The GPUs used for evaluation}.
We present the cost-efficiency of the two GPUs.
Figure \ref{fig:cost_efficiency} shows the ground truth on training GNN considering cost-efficiency.
The GPU utilization is also present at the top of each bar.
It shows that the two GPUs perform different considering each GNN framework.
DGL on V100 performs better than A100 while PyG on A100 performs better than V100.